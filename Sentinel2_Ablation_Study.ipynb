{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Sentinel2_Ablation_Study.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "environment": {
      "name": "tf2-2-3-gpu.2-3.m58",
      "type": "gcloud",
      "uri": "gcr.io/deeplearning-platform-release/tf2-2-3-gpu.2-3:m58"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ovvxtb3oAl8i"
      },
      "source": [
        "## UCB Sentinel-2 Ablation Study"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cLeCvib8Al8i"
      },
      "source": [
        "This notebook will allow you to re-run the experiment with the parameters you specify. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5b5BnvMEAl8i"
      },
      "source": [
        "### Environment and library settings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVaU__nNFgLE"
      },
      "source": [
        "# Data download, comment once complete\n",
        "%env DATA_DIR=/content\n",
        "%env DOWNLOAD_URL=http://bigearth.net/downloads/BigEarthNet-v1.0.tar.gz\n",
        "\n",
        "!rm -rf /content\n",
        "!mkdir -p $DATA_DIR\n",
        "!wget -qO- $DOWNLOAD_URL  | tar xz -C $DATA_DIR"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLAJJTmIAl8i"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3EQPp2oEAl8j"
      },
      "source": [
        "if tf.test.gpu_device_name():\n",
        "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
        "else:\n",
        "    print(\"Please install GPU version of TF\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2COKKH0fAl8j"
      },
      "source": [
        "from pathlib import Path\n",
        "from PIL import Image, ImageShow\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "import pandas as pd\n",
        "import cv2\n",
        "from skimage.transform import resize\n",
        "from tifffile import imread\n",
        "import time\n",
        "import tensorflow as tf\n",
        "\n",
        "tf.__version__"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6oxLnfn2Al8j"
      },
      "source": [
        "import os\n",
        "data_dir = os.environ.get(\"DATA_DIR\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpPx4ms5Al8j"
      },
      "source": [
        "data_dir=os.path.join(data_dir, os.listdir(data_dir)[0])\n",
        "print(data_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwDACAssAl8k"
      },
      "source": [
        "os.listdir(os.path.join(data_dir,'S2A_MSIL2A_20170613T101032_77_22'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NAHpAqwLAl8k"
      },
      "source": [
        "img_list = os.listdir(data_dir)\n",
        "img_list[0:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIxsc_eNAl8k"
      },
      "source": [
        "len(os.listdir(data_dir))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pVCe04yLAl8k"
      },
      "source": [
        "### Configuring the model parameters and constant variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vh-9M-4Z8q8m"
      },
      "source": [
        "#@title MODEL PARAMETERS\n",
        "PIXEL = 60 #@param {type:\"number\"}\n",
        "BATCH_SIZE = 32 #@param {type:\"number\"}\n",
        "BATCH_COUNT = len(img_list)//BATCH_SIZE\n",
        "EPOCH = 4 #@param {type:\"number\"}\n",
        "\n",
        "\n",
        "#@markdown List of channels. Ex: [\"B02\", \"B03\", \"B04\"]:\n",
        "CHANNELS = [\"B05\", \"B12\"] #@param "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PcsEkl788zuS"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35j7So5MAl8k"
      },
      "source": [
        "\n",
        "# B01: Coastal aerosol; 60m\n",
        "# B02: Blue; 10m\n",
        "# B03: Green; 10m\n",
        "# B04: Red; 10m\n",
        "# B05: Vegetation red edge; 20m\n",
        "# B06: Vegetation red edge; 20m\n",
        "# B07: Vegetation red edge; 20m\n",
        "# B08: NIR; 10m\n",
        "# B09: Water vapor; 60m\n",
        "# B11: SWIR; 20m\n",
        "# B12: SWIR; 20m\n",
        "# B8A: Narrow NIR; 20m\n",
        "# Reference: https://developers.google.com/earth-engine/datasets/catalog/TUBerlin_BigEarthNet_v1#bands\n",
        "\n",
        "LABEL_MAP = {'Agro-forestry areas':1,\n",
        "           'Airports':0,\n",
        "           'Annual crops associated with permanent crops':1,\n",
        "           'Bare rock':0,\n",
        "           'Beaches, dunes, sands':0,\n",
        "           'Broad-leaved forest':0,\n",
        "           'Burnt areas':0,\n",
        "           'Coastal lagoons':0,\n",
        "           'Complex cultivation patterns':1,\n",
        "           'Coniferous forest':0,\n",
        "           'Construction sites':0,\n",
        "           'Continuous urban fabric':0,\n",
        "           'Discontinuous urban fabric':0,\n",
        "           'Dump sites':0,\n",
        "           'Estuaries':0,\n",
        "           'Fruit trees and berry plantations':1,\n",
        "           'Green urban areas':0,\n",
        "           'Industrial or commercial units':0,\n",
        "           'Inland marshes':0,\n",
        "           'Intertidal flats':0,\n",
        "           'Land principally occupied by agriculture, with significant areas of natural vegetation':1,\n",
        "           'Mineral extraction sites':0,\n",
        "           'Mixed forest':0,\n",
        "           'Moors and heathland':0,\n",
        "           'Natural grassland':0,\n",
        "           'Non-irrigated arable land':0,\n",
        "           'Olive groves':1,\n",
        "           'Pastures':1,\n",
        "           'Peatbogs':0,\n",
        "           'Permanently irrigated land':1,\n",
        "           'Port areas':0,\n",
        "           'Rice fields':1,\n",
        "           'Road and rail networks and associated land':0,\n",
        "           'Salines':0,\n",
        "           'Salt marshes':0,\n",
        "           'Sclerophyllous vegetation':0,\n",
        "           'Sea and ocean':0,\n",
        "           'Sparsely vegetated areas':0,\n",
        "           'Sport and leisure facilities':0,\n",
        "           'Transitional woodland/shrub':0,\n",
        "           'Vineyards':1,\n",
        "           'Water bodies':0,\n",
        "           'Water courses':0\n",
        "           }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHuTIa8DAl8k"
      },
      "source": [
        "### Custom data generator and model building"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qw-UTde7Al8k"
      },
      "source": [
        "### custom data generator to be used for the stacking approach\n",
        "\n",
        "class Dataset(tf.keras.utils.Sequence):\n",
        "    def __init__(self, data_dir, img_list, label_map, shuffle, channels, batch_size, pixel):\n",
        "        self.img_list = img_list\n",
        "        self.data_dir = data_dir\n",
        "        self.shuffle = shuffle\n",
        "        self.batch_size = batch_size\n",
        "        self.label_map = label_map\n",
        "        self.__on_epoch_end()\n",
        "        self.channels = channels\n",
        "        self.pixel = pixel\n",
        "        # print(channels)\n",
        "\n",
        "    def __len__(self):\n",
        "        # denote the number of batches in an epoch\n",
        "        return int(np.floor(len(self.img_list))/self.batch_size)\n",
        "\n",
        "    def __on_epoch_end(self):\n",
        "        'create and update index of the images in each epoch'\n",
        "        self.indexes = np.arange(len(self.img_list))\n",
        "        if self.shuffle == True:\n",
        "            np.random.shuffle(self.indexes)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        indexes = self.indexes[index * self.batch_size: (index + 1) * self.batch_size]\n",
        "\n",
        "        img_list = [self.img_list[i] for i in indexes]\n",
        "        imgs = [self.__load_img(img_path) for img_path in img_list]\n",
        "        # label = [1 for img_path in img_list]\n",
        "        labels =[]\n",
        "\n",
        "        for img_path in img_list:\n",
        "            label = self.__generate_label(img_path, self.data_dir, self.label_map)\n",
        "            labels.append(label)\n",
        "\n",
        "        imgs = np.array(imgs)\n",
        "        labels = np.array(labels)\n",
        "\n",
        "        return imgs, labels\n",
        "\n",
        "\n",
        "    def __generate_label(self, img_path, data_dir, label_map):\n",
        "  \n",
        "        # unroll Json to get label\n",
        "        label_path = os.path.join(data_dir, img_path, img_path + '_labels_metadata.json')\n",
        "        label_data = json.load(open(label_path))\n",
        "\n",
        "        for i in label_data[\"labels\"]:\n",
        "            if label_map[i]==1:\n",
        "                return 1\n",
        "\n",
        "        return 0\n",
        "\n",
        "\n",
        "    def __load_img(self, img_path):\n",
        "\n",
        "        ch_img_list = []\n",
        "\n",
        "        for ch in self.channels:\n",
        "            ch_path = os.path.join(data_dir, img_path, img_path + '_' + ch + '.tif')\n",
        "            ch_img_list.append(imread(ch_path))\n",
        "\n",
        "        img = self.__preprocess(ch_img_list)\n",
        "\n",
        "        return img\n",
        "\n",
        "    def __preprocess(self, channels):\n",
        "\n",
        "        'preprocess and resize channels'\n",
        "\n",
        "        # dimension\n",
        "        dim = (self.pixel,self.pixel)\n",
        "        list_of_ch = []\n",
        "\n",
        "        for k in channels:\n",
        "            mat = cv2.resize(np.array(k), dim)\n",
        "\n",
        "            #print(np.array(k).shape)\n",
        "            list_of_ch.append(mat)\n",
        "\n",
        "        img = np.dstack(list_of_ch)\n",
        "\n",
        "        return img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVAFhEM_Al8k"
      },
      "source": [
        "data_gen = Dataset(data_dir, img_list, LABEL_MAP, True, CHANNELS, BATCH_SIZE, PIXEL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nK2jvtFDAl8k"
      },
      "source": [
        "data_gen.__getitem__(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1N0cigaOAl8k"
      },
      "source": [
        "img, label = data_gen.__getitem__(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygxbK9nnAl8k"
      },
      "source": [
        "print(img.shape)\n",
        "print(label.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvJnluIUAl8k"
      },
      "source": [
        "## Model setup\n",
        "\n",
        "orig_model = tf.keras.applications.ResNet50V2(include_top=True, weights=None, pooling = \"avg\", classes=1, classifier_activation='sigmoid')\n",
        "\n",
        "dense_input = None\n",
        "out = None\n",
        "\n",
        "if len(CHANNELS) >= 9:\n",
        "    # apply 2 additional feature maps (i.e., conv layers) to\n",
        "    # graudally step down the informational filtering\n",
        "    # why >= 9? because it's 3^2 \n",
        "    dense_input = tf.keras.layers.Input(shape=(PIXEL, PIXEL, len(CHANNELS)))\n",
        "    dense_filter = tf.keras.layers.Conv2D(6, 3, padding='same')(dense_input)\n",
        "    dense_filter = tf.keras.layers.Conv2D(3, 3, padding='same')(dense_input)\n",
        "    out = orig_model(dense_filter)\n",
        "elif len(CHANNELS) == 3:\n",
        "    dense_input = tf.keras.layers.Input(shape=(PIXEL, PIXEL, 3))\n",
        "    out = orig_model(dense_input)\n",
        "else:\n",
        "    dense_input = tf.keras.layers.Input(shape=(PIXEL, PIXEL, len(CHANNELS)))\n",
        "    dense_filter = tf.keras.layers.Conv2D(3, 3, padding='same')(dense_input)\n",
        "    out = orig_model(dense_filter)\n",
        "\n",
        "model = tf.keras.Model(dense_input, out)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmS40B_hAl8k"
      },
      "source": [
        "# compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy','Precision','Recall'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLKTu3ChAl8k"
      },
      "source": [
        "### Data split and model training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPWimAGIAl8k"
      },
      "source": [
        "# split train and test datasets\n",
        "train_list = img_list[:int(len(img_list)*0.8)]\n",
        "test_list = img_list[int(len(img_list)*0.8):]\n",
        "\n",
        "data_train = Dataset(data_dir, train_list, LABEL_MAP, True, CHANNELS, BATCH_SIZE, PIXEL)\n",
        "data_test = Dataset(data_dir, test_list, LABEL_MAP, False, CHANNELS, BATCH_SIZE, PIXEL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRqFnMWFAl8k"
      },
      "source": [
        "start_time = time.time()\n",
        "history = model.fit(data_train, validation_data=data_test, epochs=EPOCH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UxcOh7UCAl8l"
      },
      "source": [
        "end_time = time.time()\n",
        "print(\"--- %s seconds ---\" % (end_time - start_time))\n",
        "print(\"training completed\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "p3xHqWTWAl8l"
      },
      "source": [
        "start_time = time.time()\n",
        "evaluation = model.evaluate(data_test, batch_size=BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "SM4i-1ImAl8l"
      },
      "source": [
        "end_time = time.time()\n",
        "print(\"--- %s seconds ---\" % (end_time - start_time))\n",
        "print(\"evaluation completed\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDMHvkejAl8l"
      },
      "source": [
        "### Training outcome"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "dgFTYLz4Al8l"
      },
      "source": [
        "# list all data in history\n",
        "print(history.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "vz-f-6Z-Al8l"
      },
      "source": [
        "print(\"Training Output\")\n",
        "print(\"accuracy: \", history.history['accuracy'])\n",
        "print(\"precision: \", history.history['precision'])\n",
        "print(\"recall: \", history.history['recall'])\n",
        "print(\"loss: \", history.history['loss'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "tbvaYkmQAl8l"
      },
      "source": [
        "print(\"Validation Output\")\n",
        "print(\"accuracy: \", evaluation[1])\n",
        "print(\"precision: \", evaluation[2])\n",
        "print(\"recall: \", evaluation[3])\n",
        "print(\"loss: \", evaluation[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8yE5l7GAl8l"
      },
      "source": [
        "### Agricultural Label Counts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ZivcADGoAl8l"
      },
      "source": [
        "def count_label(data_gen, batch_count):\n",
        "    agri_count = 0\n",
        "    for i in range(batch_count):\n",
        "        _, label = data_gen.__getitem__(i)\n",
        "        batch_agri_count = np.sum(label)\n",
        "        agri_count += batch_agri_count\n",
        "        if i%1000 == 0:\n",
        "              print('Accumulated counts of the agicultural label in batch ', i, ' is ', agri_count)\n",
        "\n",
        "    return agri_count"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "B3r4FPSwAl8l"
      },
      "source": [
        "print(\"Total batches to be counted is \", BATCH_COUNT)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VupiC0WmAl8l"
      },
      "source": [
        "print(\"Total agricultural labels in the data set is \", count_label(data_gen, BATCH_COUNT))\n",
        "print(\"The total image patches \", len(os.listdir(data_dir)))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}